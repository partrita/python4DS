{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95f0a171",
   "metadata": {},
   "source": [
    "(introduction)=\n",
    "# 첫걸음\n",
    "\n",
    "데이터 과학은 원시 데이터를 이해, 통찰력 및 지식으로 전환할 수 있는 흥미로운 분야입니다. \"데이터 과학을 위한 파이썬\"의 목표는 데이터 과학을 수행할 수 있도록 파이썬에서 가장 중요한 도구와 워크플로를 배우는 데 도움을 주는 것입니다. 이 책을 읽고 나면 다양한 데이터 과학 문제에 대처할 수 있는 도구를 갖게 될 것입니다!\n",
    "\n",
    "## 무엇을 배울 것인가\n",
    "\n",
    "데이터 과학은 방대한 분야이며 단 한 권의 책을 읽는 것만으로는 모든 것을 마스터할 수 없습니다. 이 책은 가장 중요한 도구에 대한 견고한 기초와 필요한 경우 더 많은 것을 배울 수 있는 리소스를 찾을 수 있는 충분한 지식을 제공하는 것을 목표로 합니다. 일반적인 데이터 과학 프로젝트에 필요한 도구 모델은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a55374",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ef434",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# 입력 제거\n",
    "import graphviz\n",
    "\n",
    "dot = graphviz.Digraph(comment=\"데이터 과학 워크플로\")\n",
    "dot.attr(compound=\"true\")\n",
    "dot.edge(\"가져오기\", \"정리\")\n",
    "\n",
    "with dot.subgraph(name=\"cluster_0\") as c:\n",
    "    c.attr(style=\"filled\", color=\"lightgrey\")\n",
    "    c.node_attr.update(style=\"filled\", color=\"white\")\n",
    "    c.edges(\n",
    "        [(\"시각화\", \"분석\"), (\"분석\", \"변환\"), (\"변환\", \"시각화\")]\n",
    "    )\n",
    "    c.attr(label=\"이해\")\n",
    "\n",
    "dot.edge(\"정리\", \"분석\", lhead=\"cluster_0\")\n",
    "\n",
    "dot.edge(\"분석\", \"전달\", ltail=\"cluster_0\")\n",
    "\n",
    "dot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e96aa125",
   "metadata": {},
   "source": [
    "먼저 데이터를 파이썬으로 **가져와야** 합니다. 이는 일반적으로 파일, 데이터베이스 또는 웹 애플리케이션 프로그래밍 인터페이스(API)에 저장된 데이터를 가져와 파이썬의 '데이터 프레임'으로 로드하는 것을 의미합니다. 데이터 없이는 데이터 과학을 할 수 없습니다!\n",
    "\n",
    "데이터를 가져온 후에는 일반적으로 데이터를 **정리**하거나 정돈해야 합니다. 데이터를 정리한다는 것은 데이터 세트의 의미 체계와 저장 방식이 일치하는 일관된 형태로 저장하는 것을 의미합니다. 이것은 데이터가 쉽게 작업할 수 있는 형식이라는 것을 멋지게 표현한 것입니다! 소위 \"깔끔한\" 데이터는 각 열이 변수이고 각 행이 관찰인 구조화된 표 형식 데이터의 특수한 경우입니다(모든 데이터가 표 형식이 아님). 일관된 구조를 사용하면 데이터에 대한 질문에 답하는 데 노력을 집중할 수 있고 다른 함수에 적합한 형태로 데이터를 가져오는 데 어려움을 겪지 않으므로 깔끔한 데이터는 중요합니다.\n",
    "\n",
    "깔끔한 데이터가 있으면 일반적인 다음 단계는 데이터를 **변환**하는 것입니다. 변환에는 관심 있는 관찰(예: 한 도시의 모든 사람 또는 작년의 모든 데이터)을 좁히고 기존 변수의 함수인 새 변수(예: 거리와 시간에서 속도 계산)를 만들고 요약 통계 집합(예: 개수 또는 평균)을 계산하는 것이 포함됩니다.\n",
    "\n",
    "필요한 변수가 있는 깔끔한 데이터가 있으면 지식 생성의 두 가지 주요 엔진인 시각화와 분석이 있습니다. 이들은 상호 보완적인 강점과 약점을 가지고 있으므로 실제 분석에서는 이들 사이를 여러 번 반복하게 됩니다.\n",
    "\n",
    "**시각화**는 근본적으로 인간의 활동입니다. 좋은 시각화는 예상치 못한 것을 보여주거나 데이터에 대한 새로운 질문을 제기합니다. 좋은 시각화는 또한 잘못된 질문을 하고 있거나 다른 데이터를 수집해야 함을 암시할 수도 있습니다. 시각화는 당신을 놀라게 할 수 있습니다! 다양한 형태로 제공됩니다.\n",
    "\n",
    "**분석**은 이 책에서 다루기에는 너무 큰 주제입니다. 모델 실행, 통계 수행, 특정 질문에 답하기 또는 데이터에서 이야기를 끌어내는 것이 포함될 수 있습니다. 중요한 기술이지만 적용 분야에 따라 크게 달라집니다.\n",
    "\n",
    "데이터 과학의 마지막 단계는 **소통**이며, 이는 모든 데이터 분석 프로젝트에서 절대적으로 중요한 부분입니다. 결과를 다른 사람에게 전달할 수 없다면 모델과 시각화가 데이터를 이해하는 데 얼마나 도움이 되었는지는 중요하지 않습니다.\n",
    "\n",
    "이러한 모든 도구를 둘러싸고 있는 것은 **프로그래밍**입니다. 프로그래밍은 데이터 과학 프로젝트의 거의 모든 부분에서 사용하는 교차 절단 도구입니다. 성공적인 데이터 과학자가 되기 위해 전문 프로그래머가 될 필요는 없지만 프로그래밍에 대해 더 많이 배우면 일반적인 작업을 자동화하고 새로운 문제를 더 쉽게 해결할 수 있으므로 성과를 거둘 수 있습니다.\n",
    "\n",
    "모든 데이터 과학 프로젝트에서 이러한 도구를 사용하게 되지만 대부분의 프로젝트에서는 이것만으로는 충분하지 않습니다. 대략 80/20 규칙이 적용됩니다. 이 책에서 배우는 도구를 사용하여 모든 프로젝트의 약 80%를 처리할 수 있지만 나머지 20%를 처리하려면 다른 도구가 필요합니다. 이 책 전체에서 더 많은 것을 배울 수 있는 리소스를 안내해 드릴 것입니다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aabdbc7d",
   "metadata": {},
   "source": [
    "## 이 책의 구성 방식\n",
    "\n",
    "데이터 과학 도구에 대한 이전 설명은 분석에서 사용하는 순서에 따라 대략적으로 구성되어 있습니다(물론 여러 번 반복하게 될 것입니다). 그러나 우리의 경험에 따르면 *이것이 배우는 가장 좋은 방법은 아닙니다*. 데이터 수집 및 정리로 시작하는 것은 일반적으로 일상적이거나 지루하거나 이상하고 실망스러울 수 있으며, 이 두 가지 모두 새로운 주제를 배우기 시작할 때 의욕을 꺾을 수 있기 때문입니다!\n",
    "\n",
    "대신 이미 가져오고 정리된 데이터의 시각화 및 변환으로 시작하겠습니다. 그렇게 하면 자신의 데이터를 수집하고 정리할 때 그 고통이 노력할 가치가 있다는 것을 알기 때문에 동기 부여가 높게 유지될 것입니다.\n",
    "\n",
    "각 장 내에서 유사한 패턴을 따르려고 노력합니다. 몇 가지 동기 부여 예제로 시작하여 더 큰 그림을 볼 수 있도록 한 다음 세부 정보로 들어갑니다. 책의 각 섹션에는 배운 내용을 연습하는 데 도움이 되는 연습 문제가 함께 제공됩니다. 연습 문제를 건너뛰고 싶을 수도 있지만 실제 문제에 대해 연습하는 것보다 더 좋은 학습 방법은 없습니다.\n",
    "\n",
    "## 배우지 않을 내용\n",
    "\n",
    "이 책에서 다루지 않는 몇 가지 중요한 주제가 있습니다. 가능한 한 빨리 시작하고 실행할 수 있도록 필수 사항에만 집중하는 것이 중요하다고 생각합니다. 즉, 이 책이 모든 중요한 주제를 다룰 수는 없습니다.\n",
    "\n",
    "### 모델링\n",
    "\n",
    "모델링은 데이터 과학에 매우 중요하지만 큰 주제이며 안타깝게도 여기서는 그에 합당한 내용을 다룰 공간이 없습니다. 시작하기 좋은 곳으로는 [기계 학습을 위한 sklearn 튜토리얼](https://scikit-learn.org/stable/tutorial/index.html), [용감하고 진실한 사람들을 위한 인과 추론](https://matheusfacure.github.io/python-causality-handbook) 및 *경제학자를 위한 코딩*의 [회귀](https://aeturrell.github.io/coding-for-economists/econmt-regression.html) 및 [베이즈 추론](https://aeturrell.github.io/coding-for-economists/econmt-bayesian.html) 페이지가 있습니다.\n",
    "\n",
    "### 빅 데이터\n",
    "\n",
    "이 책은 작은 \"메모리 내\"(대략 노트북에서 열 수 있음을 의미) 데이터 세트에 중점을 둡니다. 작은 데이터에 대한 경험이 없으면 빅 데이터를 다룰 수 없으므로 이것이 시작하기에 적합한 곳입니다. 이 책에서 배우는 도구는 수백 메가바이트의 데이터를 쉽게 처리할 수 있으며 약간의 주의를 기울이면 일반적으로 1-2GB(기가바이트)의 데이터를 작업하는 데 사용할 수 있습니다. 일상적으로 더 큰 데이터(예: 10-100GB)로 작업하는 경우 데이터베이스와 [Ibis](https://ibis-project.org/)와 같은 도구에 대해 자세히 알아봐야 합니다.\n",
    "\n",
    "(데이터가 이보다 크면 빅 데이터 문제가 실제로는 작은 데이터 문제로 위장된 것인지 신중하게 고려하십시오. 전체 데이터 세트는 클 수 있지만 특정 질문에 답하는 데 필요한 데이터는 종종 작습니다. 메모리에 맞는 하위 집합, 하위 표본 또는 요약을 찾아 여전히 관심 있는 질문에 답할 수 있습니다. 여기서 어려운 점은 올바른 작은 데이터를 찾는 것이며 종종 많은 반복이 필요합니다.)\n",
    "\n",
    "또 다른 가능성은 빅 데이터 문제가 실제로는 많은 작은 데이터 문제로 위장된 것일 수 있다는 것입니다. 각 개별 문제는 메모리에 맞을 수 있지만 수백만 개의 문제가 있습니다. 예를 들어 데이터 세트의 각 사람에게 모델을 맞추고 싶을 수 있습니다. 10명 또는 100명만 있다면 사소한 일이겠지만 대신 백만 명이 있습니다. 다행히 각 문제는 다른 문제와 독립적입니다(때때로 당혹스러울 정도로 병렬이라고 하는 설정). 따라서 다른 컴퓨터에 다른 데이터 세트를 보내 처리할 수 있는 시스템([Hadoop](https://hadoop.apache.org/) 또는 [Spark](https://spark.apache.org/) 등)만 있으면 됩니다. 이 책에서 설명하는 도구를 사용하여 단일 하위 집합에 대한 질문에 답하는 방법을 알아낸 후에는 **pyspark**와 같은 새로운 도구를 배워 전체 데이터 세트에 대해 해결할 수 있습니다.\n",
    "\n",
    "### 줄리아와 R\n",
    "\n",
    "이 책에서는 데이터 과학에 때때로 사용되는 R이나 줄리아에 대해서는 아무것도 배우지 않습니다. 이것은 이러한 도구가 나쁘다고 생각하기 때문이 아닙니다. 그렇지 않습니다! 이 책에서는 데이터 과학에 대한 세 가지 중요한 도구라고 생각하는 것을 보게 될 것입니다.\n",
    "\n",
    "- 파이썬\n",
    "- SQL\n",
    "- 명령줄 스크립팅\n",
    "\n",
    "이 세 가지 언어는 데이터 과학자로서 일자리를 얻는 데 도움이 될 것이며, 이것이 이들에 집중하는 매우 좋은 이유입니다. 우리는 대부분의 시간을 파이썬과 함께 보낼 것이며 그럴 만한 이유가 있습니다. 파이썬은 일반적으로 세계에서 첫 번째 또는 두 번째로 인기 있는 프로그래밍 언어로 평가되며, 마찬가지로 중요한 것은 배우기 가장 쉬운 언어 중 하나이기도 합니다. 범용 언어이므로 다양한 작업을 수행할 수 있습니다. 이러한 기능의 조합 때문에 사람들은 파이썬이 바닥은 낮고 천장은 높다고 말합니다. 또한 매우 다재다능합니다. 파이썬은 모든 것에서 두 번째로 좋은 언어라는 농담이 있으며 어느 정도 사실입니다(기계 학습과 같은 일부 작업에서는 파이썬이 최고이지만). 그러나 그렇게 많은 분야를 다루는 언어는 매우 유용하며 파이썬은 산업, 학계 및 공공 부문 전반에 걸쳐 널리 사용되며 학교에서도 종종 가르칩니다.\n",
    "\n",
    "파이썬은 데이터 과학 및 프로그래밍 전반에 걸쳐 가장 인기 있는 도구이며 그 뒤에 큰 커뮤니티가 있으므로 데이터 과학 여정을 시작하기에 좋은 곳이라고 생각합니다.\n",
    "\n",
    "## 이 책에 대한 세부 정보\n",
    "\n",
    "이 책은 다음 버전의 파이썬으로 컴파일되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26faf349",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# 입력 제거\n",
    "import sys\n",
    "\n",
    "print(\"파이썬 버전으로 컴파일됨:\", sys.version)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "937d7b82",
   "metadata": {},
   "source": [
    "## 감사의 말\n",
    "\n",
    "이 책은 [데이터 과학을 위한 R (2e)](https://r4ds.hadley.nz/) 책을 매우 가깝게 재현한 것이며 데이터 과학을 더 쉽게 소화할 수 있는 책으로 만들기 위한 노력에 영감을 받았습니다."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "md:myst",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
